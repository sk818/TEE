#!/usr/bin/env python3
"""
Download Tessera embeddings for current viewport

Reads viewport bounds from active viewport configuration.
Uses cache checking to avoid re-downloading for previously-selected viewports.
"""

import sys
import json
import traceback
from pathlib import Path

# Add parent directory to path for lib imports
sys.path.insert(0, str(Path(__file__).parent))

# Import dependencies with error reporting
try:
    import gc
    import numpy as np
    import rasterio
    from rasterio.transform import Affine
    import geotessera as gt
    import math
except ImportError as e:
    print(f"IMPORT ERROR: {e}", file=sys.stderr)
    traceback.print_exc(file=sys.stderr)
    sys.exit(1)

try:
    from lib.viewport_utils import get_active_viewport, check_cache
    from lib.progress_tracker import ProgressTracker
    from lib.config import DATA_DIR, EMBEDDINGS_DIR, MOSAICS_DIR
except ImportError as e:
    print(f"LIB IMPORT ERROR: {e}", file=sys.stderr)
    traceback.print_exc(file=sys.stderr)
    sys.exit(1)

# Configuration
DEFAULT_YEARS = range(2017, 2026)  # Support 2017-2025 (Sentinel-2 availability)

# Parse command line arguments for year selection
import argparse
parser = argparse.ArgumentParser(description='Download Tessera embeddings')
parser.add_argument('--years', type=str, help='Comma-separated years to download (e.g., 2017,2018,2024)')
args = parser.parse_args()

if args.years:
    try:
        # Parse comma-separated years and convert to integers
        requested_years = sorted([int(y.strip()) for y in args.years.split(',') if y.strip()])
        if requested_years:
            YEARS = requested_years
        else:
            YEARS = DEFAULT_YEARS
    except (ValueError, IndexError):
        YEARS = DEFAULT_YEARS
else:
    YEARS = DEFAULT_YEARS

# Tessera embeddings parameters
EMBEDDING_BANDS = 128
BYTES_PER_BAND = 4  # float32
PIXEL_SIZE_METERS = 10
METERS_PER_DEGREE_LAT = 111320  # Constant
COMPRESSION_RATIO = 0.4  # LZW compression typically achieves ~40% of original size

def estimate_mosaic_dimensions(bbox):
    """Estimate mosaic dimensions from bounding box.

    Args:
        bbox: tuple of (lon_min, lat_min, lon_max, lat_max)

    Returns:
        tuple of (estimated_width, estimated_height, estimated_file_size_mb)
    """
    lon_min, lat_min, lon_max, lat_max = bbox

    # Calculate center latitude for longitude scaling
    center_lat = (lat_min + lat_max) / 2
    cos_lat = math.cos(math.radians(center_lat))

    # Meters per degree at this latitude
    meters_per_degree_lon = METERS_PER_DEGREE_LAT * cos_lat

    # Calculate dimensions in pixels
    height_pixels = int((lat_max - lat_min) * METERS_PER_DEGREE_LAT / PIXEL_SIZE_METERS)
    width_pixels = int((lon_max - lon_min) * meters_per_degree_lon / PIXEL_SIZE_METERS)

    # Calculate uncompressed file size (width Ã— height Ã— bands Ã— bytes_per_band)
    uncompressed_bytes = width_pixels * height_pixels * EMBEDDING_BANDS * BYTES_PER_BAND

    # Estimate compressed size with LZW compression
    compressed_bytes = int(uncompressed_bytes * COMPRESSION_RATIO)
    compressed_mb = compressed_bytes / (1024 * 1024)

    return width_pixels, height_pixels, compressed_mb, compressed_bytes

def download_embeddings():
    """Download Tessera embeddings for current viewport."""

    # Read active viewport
    try:
        viewport = get_active_viewport()
        BBOX = viewport['bounds_tuple']
        viewport_id = viewport['viewport_id']
    except Exception as e:
        print(f"ERROR: Failed to read viewport: {e}", file=sys.stderr)
        sys.exit(1)

    # Initialize progress tracker - use script-specific progress file to avoid conflicts with pipeline orchestrator
    progress = ProgressTracker(f"{viewport_id}_download")
    progress.update("starting", f"Initializing download for {viewport_id}...")

    # Create output directories
    EMBEDDINGS_DIR.mkdir(exist_ok=True)
    MOSAICS_DIR.mkdir(exist_ok=True)

    print(f"Downloading Tessera embeddings")
    print(f"Viewport: {viewport_id}")
    print(f"Bounding box: {BBOX}")
    print(f"Years: {min(YEARS)} to {max(YEARS)}")

    # Estimate file size and dimensions
    est_width, est_height, est_mb, est_bytes = estimate_mosaic_dimensions(BBOX)
    print(f"\nEstimated dimensions: {est_width} Ã— {est_height} pixels")
    print(f"Estimated file size (compressed): {est_mb:.1f} MB")

    print(f"\nEmbeddings will be downloaded to: {EMBEDDINGS_DIR.absolute()}")
    print(f"Mosaics will be saved to: {MOSAICS_DIR.absolute()}")
    print("=" * 60)

    # Initialize GeoTessera with embeddings directory
    print(f"\nConnecting to GeoTessera registry...")
    print(f"   geotessera version: {gt.__version__ if hasattr(gt, '__version__') else 'unknown'}")
    print(f"   embeddings_dir: {EMBEDDINGS_DIR.absolute()}")
    progress.update("initializing", "Connecting to GeoTessera registry...")
    try:
        tessera = gt.GeoTessera(embeddings_dir=str(EMBEDDINGS_DIR))
        print(f"âœ“ Connected to registry")
    except Exception as e:
        print(f"âœ— Failed to connect to GeoTessera: {type(e).__name__}: {e}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)
        progress.error(f"GeoTessera connection failed: {e}")
        sys.exit(1)

    # Track successful downloads for metadata
    successful_years = []

    # Calculate total estimated size across all years for cumulative progress
    total_years = len(list(YEARS))
    total_estimated_bytes = est_bytes * total_years
    cumulative_bytes_done = 0  # Track progress across all years

    for year_idx, year in enumerate(YEARS):
        print(f"\nðŸ“… Processing year {year}...")

        # Use viewport-specific filename for proper caching across viewports
        output_file = MOSAICS_DIR / f"{viewport_id}_embeddings_{year}.tif"

        print(f"   Target file: {output_file.name}")
        print(f"   Expected size: {est_mb:.1f} MB")
        progress.update("processing", f"Year {year_idx+1}/{total_years}: Processing {year}...",
                       current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)

        # Check cache for matching bounds
        cached_file = check_cache(BBOX, 'embeddings')
        if cached_file:
            print(f"   âœ“ Cache hit! Using existing mosaic: {cached_file}")
            cumulative_bytes_done += est_bytes
            progress.update("processing", f"Year {year_idx+1}/{total_years}: Using cached {year}",
                           current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)
            successful_years.append(year)
            continue

        if output_file.exists():
            print(f"   âœ“ Mosaic already exists: {output_file}")
            actual_size_mb = output_file.stat().st_size / (1024 * 1024)
            print(f"     Actual size: {actual_size_mb:.1f} MB")
            cumulative_bytes_done += est_bytes
            progress.update("processing", f"Year {year_idx+1}/{total_years}: Using existing {year}",
                           current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)
            successful_years.append(year)
            continue

        # Calculate exact download requirements using geotessera registry (dry-run equivalent)
        try:
            print(f"   Querying tile registry...")
            progress.update("initializing", f"Year {year_idx+1}/{total_years}: Querying tiles for {year}...",
                           current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)
            tiles = list(tessera.registry.iter_tiles_in_region(BBOX, year))
            print(f"   Calculating download size ({len(tiles)} tiles)...")
            progress.update("initializing", f"Year {year_idx+1}/{total_years}: Calculating size for {year}...",
                           current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)
            total_download_bytes, total_files, _ = tessera.registry.calculate_download_requirements(
                tiles, EMBEDDINGS_DIR, format_type='npy', check_existing=True
            )
            total_download_mb = total_download_bytes / (1024 * 1024)
            print(f"   Download required: {total_files} files, {total_download_mb:.1f} MB")
        except Exception as e:
            print(f"   âš ï¸  Could not calculate download size: {e}")
            total_download_bytes = est_bytes  # Fall back to estimate
            total_files = 0

        # Track bytes downloaded for accurate progress
        bytes_downloaded = [0]  # Use list for closure

        # Retry logic for download and validation
        max_retries = 3
        year_success = False

        for attempt in range(1, max_retries + 1):
            try:
                print(f"   Downloading and merging tiles (attempt {attempt}/{max_retries})...")
                progress.update("downloading", f"Year {year_idx+1}/{total_years}: Downloading {year} (0.0 / {total_download_mb:.1f} MB)",
                               current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)

                # Define progress callback with byte-based tracking (cumulative across all years)
                def on_geotessera_progress(current, total, status, year=year, year_idx=year_idx, cumulative=cumulative_bytes_done, total_mb=total_download_mb):
                    # Estimate bytes based on tile progress (current/total * total_bytes)
                    if total > 0:
                        year_bytes = int((current / total) * total_download_bytes)
                        bytes_downloaded[0] = year_bytes
                        overall_bytes = cumulative + year_bytes
                        year_mb_done = year_bytes / (1024*1024)
                        progress.update("downloading",
                                       f"Year {year_idx+1}/{total_years}: {year} - {status} ({year_mb_done:.1f} / {total_mb:.1f} MB)",
                                       current_value=overall_bytes,
                                       total_value=total_estimated_bytes,
                                       current_file=f"{output_file.name}")

                # Fetch mosaic for the region (auto-downloads missing tiles)
                mosaic_array, mosaic_transform, crs = tessera.fetch_mosaic_for_region(
                    bbox=BBOX,
                    year=year,
                    target_crs='EPSG:4326',
                    auto_download=True,
                    progress_callback=on_geotessera_progress
                )

                print(f"   âœ“ Downloaded. Mosaic shape: {mosaic_array.shape}")
                print(f"   Saving to GeoTIFF: {output_file}")

                # Save mosaic to GeoTIFF
                height, width, bands = mosaic_array.shape
                progress.update("saving", f"Year {year_idx+1}/{total_years}: Saving {year} to disk...",
                               current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)

                with rasterio.open(
                    output_file,
                    'w',
                    driver='GTiff',
                    height=height,
                    width=width,
                    count=bands,
                    dtype=mosaic_array.dtype,
                    crs=crs,
                    transform=mosaic_transform,
                    compress='lzw'
                ) as dst:
                    # Write each band (no progress update to avoid bar jumping)
                    for band in range(bands):
                        dst.write(mosaic_array[:, :, band], band + 1)

                # Validate the saved file
                print(f"   Validating TIFF file...")
                try:
                    with rasterio.open(output_file) as src:
                        _ = src.read(1)  # Try reading first band
                    print(f"   âœ“ File validation successful")

                    # Report actual file size and update cumulative progress
                    actual_size_mb = output_file.stat().st_size / (1024 * 1024)
                    print(f"   File size: {actual_size_mb:.1f} MB (estimated: {est_mb:.1f} MB)")
                    cumulative_bytes_done += est_bytes
                    progress.update("processing", f"Year {year_idx+1}/{total_years}: âœ“ Saved {year} ({actual_size_mb:.1f} MB)",
                                   current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)
                    year_success = True
                    del mosaic_array, mosaic_transform
                    gc.collect()
                    break  # File is valid, exit retry loop
                except Exception as val_error:
                    print(f"   âœ— File validation failed: {val_error}")
                    output_file.unlink()  # Delete corrupted file
                    if attempt < max_retries:
                        progress.update("processing", f"Year {year_idx+1}/{total_years}: Retrying {year} (corrupted)...",
                                       current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)
                        import time
                        time.sleep(5)  # Wait before retry
                        continue
                    else:
                        progress.error(f"File corrupted after {max_retries} attempts for {year}")
                        raise Exception(f"Corrupted file: {val_error}")

            except Exception as e:
                if attempt == max_retries:
                    print(f"   âš ï¸  Year {year} not available: {type(e).__name__}: {e}")
                    print(f"   Traceback for {year}:", file=sys.stderr)
                    traceback.print_exc(file=sys.stderr)
                    cumulative_bytes_done += est_bytes  # Count as done even if skipped
                    progress.update("processing", f"Year {year_idx+1}/{total_years}: Skipped {year} (not available)",
                                   current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)
                    break
                else:
                    print(f"   âš ï¸  Attempt {attempt} failed, retrying: {type(e).__name__}: {e}")
                    progress.update("processing", f"Year {year_idx+1}/{total_years}: Retrying {year}...",
                                   current_file=output_file.name, current_value=cumulative_bytes_done, total_value=total_estimated_bytes)
                    import time
                    time.sleep(5)  # Wait before retry
                    continue

        # Track successful downloads
        if output_file.exists() and year_success:
            size_mb = output_file.stat().st_size / (1024*1024)
            print(f"   âœ“ Saved: {output_file} ({size_mb:.2f} MB)")
            successful_years.append(year)

    print("\n" + "=" * 60)
    print("Download complete!")
    print(f"\nTiles cached in: {EMBEDDINGS_DIR.absolute()}")
    print(f"Mosaics saved in: {MOSAICS_DIR.absolute()}")

    # Save metadata about successful downloads
    metadata_file = MOSAICS_DIR / f"{viewport_id}_years.json"
    metadata = {'available_years': sorted(successful_years)}
    with open(metadata_file, 'w') as f:
        json.dump(metadata, f)
    print(f"âœ“ Saved metadata: {metadata_file}")
    print(f"Successfully downloaded years: {sorted(successful_years)}")

    # Check if any mosaics were successfully created
    if successful_years:
        print(f"\nâœ“ Created mosaics for {viewport_id}:")
        total_size_mb = 0
        for year in successful_years:
            mosaic_file = MOSAICS_DIR / f"{viewport_id}_embeddings_{year}.tif"
            if mosaic_file.exists():
                size_mb = mosaic_file.stat().st_size / (1024*1024)
                total_size_mb += size_mb
                compression_ratio = (size_mb / (est_mb / COMPRESSION_RATIO)) * 100 if est_mb > 0 else 0
                print(f"  - {mosaic_file.name} ({size_mb:.1f} MB, {compression_ratio:.1f}% compression)")
        print(f"\nTotal downloaded: {total_size_mb:.1f} MB for {len(successful_years)} years")
        progress.complete(f"Downloaded {total_size_mb:.1f} MB of embeddings ({len(successful_years)} years)")
    else:
        error_msg = f"No mosaics for {viewport_id} were created (all downloads failed for years: {list(YEARS)})"
        print(f"\nâœ— Error: {error_msg}")
        print(f"ERROR: {error_msg}", file=sys.stderr)
        progress.error(f"Failed to download embeddings for any year")
        sys.exit(1)

if __name__ == "__main__":
    import traceback
    try:
        download_embeddings()
    except SystemExit:
        raise  # Let sys.exit() propagate normally
    except Exception as e:
        print(f"\nFATAL ERROR in download_embeddings: {type(e).__name__}: {e}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)
        sys.exit(1)
